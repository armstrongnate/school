# AI Notes
## Wed Aug 27
### Get the Book
DJ says the book is effective. Buy it. Read it. Live it.

### Types of agents
* reflex: 1 percept becomes 1 action
  - model based reflex agent: pays more attention
* goal: has a destination in mind
* utility: goal based with a happiness factor
  - _happy_ means how the agent thinks it is doing
  - utility functions tries to determine _how well am i doing?_ or, how
    happy am I?
  - competitive agents are happy when its competitors are not happy

### Environments
Attributes of what an environment might be.
* Fully-oversvable vs partially
  - fully example: chess board
  - partially example: earth
* Single-agent vs multi-agent
  - single: crossword puzzle
  - multi: chinese checkers
  - something thats performance effects your performance constitutes
    another agent
* Deterministic vs stocastic
  - deterministic: i can predict what will happen to the environment
    based on my action eg chinese checkers
  - stocastic: example is real world. complex environments
  - **You can have a partially observable deterministic environment.**
* Episodic vs sequential
  - episodic: one percept then one action. rinse and repeat, eg picking
    cherries
  - sequential: percepts and actions build on each other, eg board game
* Static vs dynamic
  - static: environment does not change while you think
  - dynamic: environment can change while you think
* Discrete vs continuous
  - discrete: something about the world is discrete. _Im either standing
    here or there. not inbetween_.
  - continuous: real world. you can stand anywhere.
* Known vs unknown
  - known: has an idea of what is going to happen
  - unknown: agent is handed an xbox remote but has never played halo.
    No idea what is going to happen

### Homework
* Study and learn these environments.
